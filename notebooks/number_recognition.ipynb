{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions.plot_images import plot_images\n",
    "from functions.model_cnn import train_and_eval_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download mnist dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split the training data into a training and validation set using train_test_split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the shape of the training, validation, and test sets\n",
    "for dataset, images in zip(['Training', 'Validation', 'Test'], [train_images, val_images, test_images]):\n",
    "    print(f'{dataset} images shape: {images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 5 labels from each of the training, validation, and test sets\n",
    "for dataset, images, labels in zip(['Training', 'Validation', 'Test'], [train_images, val_images, test_images], [train_labels, val_labels, test_labels]):\n",
    "    print(f'{dataset} set 5 first images:')\n",
    "    plot_images(images[:5], labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channel dimension to the images ti fit model entry\n",
    "X_train = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "X_val = val_images.reshape(val_images.shape[0], 28, 28, 1)\n",
    "X_test = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to 48x48\n",
    "X_train = np.array([cv2.resize(img, (48,48)) for img in X_train])\n",
    "X_val = np.array([cv2.resize(img, (48,48)) for img in X_val])\n",
    "X_test = np.array([cv2.resize(img, (48,48)) for img in X_test])\n",
    "X_train = X_train.reshape(-1, 48, 48, 1)\n",
    "X_val = X_val.reshape(-1, 48, 48, 1)\n",
    "X_test = X_test.reshape(-1, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "X_test = X_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first image's new shape for verification\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-plot the first 5 labels from each of the training, validation, and test sets\n",
    "for dataset, images, labels in zip(['Training', 'Validation', 'Test'], [X_train, X_val, X_test], [train_labels, val_labels, test_labels]):\n",
    "    print(f'{dataset} set 5 first images:')\n",
    "    plot_images(images[:5], labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = to_categorical(train_labels, NUM_CLASSES)\n",
    "y_val = to_categorical(val_labels, NUM_CLASSES)\n",
    "y_test = to_categorical(test_labels, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN MODEL CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and evaluate the CNN model (functions in functions repo) => to be improved in changing the parameters directly in notebook\n",
    "model = train_and_eval_CNN(X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN MODEL CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in keras\n",
    "model.save('number_recon_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
